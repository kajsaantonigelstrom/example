Step 1 : Develop a Recipe

Create a Job file by hand:
line 1 : Full path to the folder where the brain data are
Line 2-n : The recipe 

From command line, go to the pipeworker folder:
cd <...>/example/pipeworker

To test the Recipe:
python pipejob.py <full path to the job file>

2a : Start Pipeworkers on the servers you want to use.
Prerequisites: 
- All software needed to run the recipe must be installed on the server
- The two python scripts 'pipeworker.py' and 'pipejob.py' copied to the server
  (Copy them to the folder where you come with the ssh command)
- In the same folder as pipeworker.py, create the pipeworker.cfg file
  line 1 : Full path to the Job Folder
  line 2 : Max number of concurrent jobs for this server

2b : Start the PipeMonitor on the control computer
- Create a recipe (Function menu : Handle recipes) and copy the Recipe part of your tested job file
- Check that Job Folder and Brains Folder are correct (bottom part of the Monitor window)
- Start the jobs (Function menu : Generate jobs). In the combobox, select the Recipe you want to run and press
  Generate jobs


Recipe cookbook:
1. You can use %BRAIN% in your recipe to refer to the current brain 
sub-folder.
2. You can use %BRAINFOLDER% in your recipe to refer to the 'Brains Folder'
(as seen at the bottom of the pipemonitor UI.)
3. You can add your own %X% by writing
.DEFINE X=hej
After this %X% will mean 'hej' in the recipe.
4. Another way to do the same is the 'export' statement
export X=hej
The difference is that this will be added to the 'process environment' and thus
be accessable by subsequent commands in recipe
5. If you install the MatLab application you can call matlab functions from the recipe, ex:
MATLAB /home/suit.m filename=2_T1w_MPR.nii RET=errvalue
This will run the script 'suit.m'. It will set the variable 'filename' in the matlab
workspace. And it will try to find the variable 'errvalue' in the workspace and return this
to the pipeworker system.
